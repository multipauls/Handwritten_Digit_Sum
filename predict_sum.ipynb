{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z5ogE7al7FMv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "LV3oaz6WPEE1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "IIZEkv9BoKD9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDoNO3ty-hZZ",
        "outputId": "9b82e2a6-294d-4e86-c143-8e8a2b503c6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5jYJQSX97SVX"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32 , kernel_size=7, padding=1, stride=(1,1))\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32 , kernel_size=7, padding=1, stride=(1,1))\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.pad = nn.ZeroPad2d((3, 3))\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.fc = nn.Linear(4160,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "       \n",
        "        x = self.pad(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = x.view(-1, 4160)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _,preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n"
      ],
      "metadata": {
        "id": "29_mGp-EPCkX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    mnist_train = datasets.MNIST('./', train=True, download=True, transform=transforms.ToTensor())\n",
        "    mnist_test= datasets.MNIST('./', train=False, download=True, transform=transforms.ToTensor())\n",
        "    cnn = CNN().to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
        "\n",
        "    batch_size = 1\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "    testloader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    accur = []\n",
        "    for epoch in range(5):  \n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = cnn(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 1000 == 999:    # print every 1000 batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                running_loss = 0.0\n",
        "        acc = []\n",
        "        for j, data in enumerate(testloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = cnn(inputs)\n",
        "            acc.append(accuracy(outputs, labels))\n",
        "        print(torch.stack(acc).mean())\n",
        "        accur.append(torch.stack(acc).mean())\n",
        "    print('Finished Training, saving')\n",
        "    torch.save(cnn, '/content/drive/My Drive/ML4NS1/cnn_mnist')\n",
        "    print(\"Saved\")"
      ],
      "metadata": {
        "id": "do8k2osEPJMV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "CE6y1h0OPM98"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "id": "yyifDmNmY79k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y4d8g5qH7Rto"
      },
      "outputs": [],
      "source": [
        "train_data0 = np.load('/content/drive/My Drive/ML4NS1/data0.npy')\n",
        "train_lab0 = np.load('/content/drive/My Drive/ML4NS1/lab0.npy')\n",
        "train_data1 = np.load('/content/drive/My Drive/ML4NS1/data1.npy')\n",
        "train_lab1 = np.load('/content/drive/My Drive/ML4NS1/lab1.npy')\n",
        "train_data2 = np.load('/content/drive/My Drive/ML4NS1/data2.npy')\n",
        "train_lab2 = np.load('/content/drive/My Drive/ML4NS1/lab2.npy')\n",
        "\n",
        "train_data = np.concatenate((train_data0, train_data1, train_data2))\n",
        "train_lab = np.concatenate((train_lab0, train_lab1, train_lab2))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def deskew(img):\n",
        "    m = cv2.moments(img)\n",
        "    if abs(m['mu02']) < 1e-2:\n",
        "        return img.copy()\n",
        "    skew = m['mu11']/m['mu02']\n",
        "    M = np.float32([[1, skew, -0.5*28*skew], [0, 1, 0]])\n",
        "    img = cv2.warpAffine(img, M, (28, 28), flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "UDCX7ptjXUUd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(image):\n",
        "    ret, thresh = cv2.threshold(image,50,150,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    connectivity = 8  \n",
        "    output = cv2.connectedComponentsWithStats(thresh, connectivity, cv2.CV_32S)\n",
        "    stats = output[2]\n",
        "    segments = []\n",
        "    for i in range(1,len(stats)):\n",
        "        l,t,w,h,a = stats[i]\n",
        "        cropped = image[t:t+h,l:l+w]\n",
        "        if a >= 30:\n",
        "            if w > 22 and w<=37:\n",
        "                splitted1=image[t:t+h, l:l+int(w/2)]\n",
        "                splitted2=image[t:t+h, l+int(w/2):l+w]\n",
        "\n",
        "                splitted1 = cv2.resize(splitted1, (0,0), fx=0.78, fy=0.78, interpolation = cv2.INTER_AREA) \n",
        "                splitted2 = cv2.resize(splitted2, (0,0), fx=0.78, fy=0.78, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "                pad_shape = np.array([28, 28]) - np.array(splitted1.shape)\n",
        "                splitted1 = np.pad(splitted1, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                splitted1 = deskew(splitted1)\n",
        "                segments.append(splitted1)\n",
        "\n",
        "                pad_shape = np.array([28, 28]) - np.array(splitted2.shape)\n",
        "                splitted2 = np.pad(splitted2, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                splitted2 = deskew(splitted2)\n",
        "                segments.append(splitted2)\n",
        "            \n",
        "            elif w>37:\n",
        "                splitted1=image[t:t+h, l:l+int(w/3)]\n",
        "                splitted2=image[t:t+h, l+int(w/3):l+int(2*w/3)]\n",
        "                splitted3=image[t:t+h, l+int(2*w/3):l+w]\n",
        "\n",
        "                splitted1 = cv2.resize(splitted1, (0,0), fx=0.78, fy=0.78, interpolation = cv2.INTER_AREA) \n",
        "                splitted2 = cv2.resize(splitted2, (0,0), fx=0.78, fy=0.78, interpolation = cv2.INTER_AREA)\n",
        "                splitted3 = cv2.resize(splitted3, (0,0), fx=0.78, fy=0.78, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "                pad_shape = np.array([28, 28]) - np.array(splitted1.shape)\n",
        "                splitted1 = np.pad(splitted1, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                splitted1 = deskew(splitted1)\n",
        "                segments.append(splitted1)\n",
        "\n",
        "                pad_shape = np.array([28, 28]) - np.array(splitted2.shape)\n",
        "                splitted2 = np.pad(splitted2, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                splitted2 = deskew(splitted2)\n",
        "                segments.append(splitted2)\n",
        "\n",
        "                pad_shape = np.array([28, 28]) - np.array(splitted3.shape)\n",
        "                splitted3 = np.pad(splitted3, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                splitted3 = deskew(splitted3)\n",
        "                segments.append(splitted3)\n",
        "\n",
        "            else:\n",
        "                if h>28:\n",
        "                    cropped = cv2.resize(cropped, (0,0), fx=0.8, fy=0.8, interpolation = cv2.INTER_AREA)\n",
        "                pad_shape = np.array([28, 28]) - np.array(cropped.shape)\n",
        "                cropped = np.pad(cropped, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                cropped = deskew(cropped)\n",
        "                segments.append(cropped)\n",
        "    return segments\n",
        "    "
      ],
      "metadata": {
        "id": "8s-6S1qswlam"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model_path, train_data, train_lab):\n",
        "    predictor = torch.load(model_path)\n",
        "    predictor.to(device)\n",
        "    acc = []\n",
        "    counter = 0\n",
        "    falsectr = 0\n",
        "    for i in range(len(train_data)):\n",
        "        img = train_data[i]\n",
        "        labels = train_lab[i]     \n",
        "        inputs = split(img)\n",
        "        sum = 0\n",
        "        digits = []\n",
        "        for j in range(len(inputs)):\n",
        "            image = torch.from_numpy(inputs[j])\n",
        "            image = torch.reshape(image, (1,1,28,28)).float()\n",
        "            outputs = predictor(image.to(device))\n",
        "            digit = torch.argmax(outputs)\n",
        "            digits.append(digit)\n",
        "            sum += digit\n",
        "        if sum == labels:\n",
        "            counter+=1\n",
        "        if i % 500 == 499:    # print every 5000\n",
        "                print('%d, accuracy: %.3f' %\n",
        "                        ( i+1, counter*100 / i))\n",
        "    print(\"Final accuracy \"+str(counter*100/len(train_data))+\"%\")\n"
      ],
      "metadata": {
        "id": "vD2EFyv2ASLE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict('/content/drive/My Drive/ML4NS1/cnn_mnist',  train_data, train_lab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYY33VJygWqm",
        "outputId": "0b6ed4df-c8fb-4992-e003-df96f3d138ad"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500, accuracy: 63.928\n",
            "1000, accuracy: 64.765\n",
            "1500, accuracy: 64.243\n",
            "2000, accuracy: 63.582\n",
            "2500, accuracy: 62.745\n",
            "3000, accuracy: 63.288\n",
            "3500, accuracy: 63.818\n",
            "4000, accuracy: 64.241\n",
            "4500, accuracy: 64.570\n",
            "5000, accuracy: 64.333\n",
            "5500, accuracy: 64.394\n",
            "6000, accuracy: 64.061\n",
            "6500, accuracy: 63.933\n",
            "7000, accuracy: 63.952\n",
            "7500, accuracy: 63.742\n",
            "8000, accuracy: 63.620\n",
            "8500, accuracy: 63.607\n",
            "9000, accuracy: 63.396\n",
            "9500, accuracy: 63.459\n",
            "10000, accuracy: 63.436\n",
            "10500, accuracy: 63.397\n",
            "11000, accuracy: 63.451\n",
            "11500, accuracy: 63.449\n",
            "12000, accuracy: 63.514\n",
            "12500, accuracy: 63.397\n",
            "13000, accuracy: 63.336\n",
            "13500, accuracy: 63.345\n",
            "14000, accuracy: 63.226\n",
            "14500, accuracy: 63.184\n",
            "15000, accuracy: 63.198\n",
            "15500, accuracy: 63.223\n",
            "16000, accuracy: 63.298\n",
            "16500, accuracy: 63.319\n",
            "17000, accuracy: 63.286\n",
            "17500, accuracy: 63.284\n",
            "18000, accuracy: 63.381\n",
            "18500, accuracy: 63.355\n",
            "19000, accuracy: 63.340\n",
            "19500, accuracy: 63.388\n",
            "20000, accuracy: 63.308\n",
            "20500, accuracy: 63.330\n",
            "21000, accuracy: 63.246\n",
            "21500, accuracy: 63.268\n",
            "22000, accuracy: 63.298\n",
            "22500, accuracy: 63.296\n",
            "23000, accuracy: 63.277\n",
            "23500, accuracy: 63.262\n",
            "24000, accuracy: 63.269\n",
            "24500, accuracy: 63.190\n",
            "25000, accuracy: 63.243\n",
            "25500, accuracy: 63.238\n",
            "26000, accuracy: 63.237\n",
            "26500, accuracy: 63.331\n",
            "27000, accuracy: 63.339\n",
            "27500, accuracy: 63.366\n",
            "28000, accuracy: 63.409\n",
            "28500, accuracy: 63.420\n",
            "29000, accuracy: 63.430\n",
            "29500, accuracy: 63.406\n",
            "30000, accuracy: 63.425\n",
            "Final accuracy 63.42333333333333%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-LTA_uBvsnSW"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fbEqWG4rwU-Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "ML4NS_Assign1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}