{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z5ogE7al7FMv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "LV3oaz6WPEE1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "IIZEkv9BoKD9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDoNO3ty-hZZ",
        "outputId": "ffb94dbb-c352-4cf2-adc4-207ce8b0523d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5jYJQSX97SVX"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32 , kernel_size=7, padding=1, stride=(1,1))\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32 , kernel_size=7, padding=1, stride=(1,1))\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.pad = nn.ZeroPad2d((3, 3))\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.fc = nn.Linear(4160,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "       \n",
        "        x = self.pad(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = x.view(-1, 4160)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _,preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n"
      ],
      "metadata": {
        "id": "29_mGp-EPCkX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    mnist_train = datasets.MNIST('./', train=True, download=True, transform=transforms.ToTensor())\n",
        "    mnist_test= datasets.MNIST('./', train=False, download=True, transform=transforms.ToTensor())\n",
        "    cnn = CNN().to(device)\n",
        "\n",
        "    loss_plot = []\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
        "\n",
        "    batch_size = 1\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "    testloader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    accur = []\n",
        "    for epoch in range(5):  \n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = cnn(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 1000 == 999:    # print every 1000 batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                loss_plot.append(running_loss)\n",
        "                running_loss = 0.0\n",
        "\n",
        "        acc = []\n",
        "        for j, data in enumerate(testloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = cnn(inputs)\n",
        "            acc.append(accuracy(outputs, labels))\n",
        "        print(torch.stack(acc).mean())\n",
        "        accur.append(torch.stack(acc).mean())\n",
        "    print('Finished Training, saving')\n",
        "    #torch.save(cnn, '/content/drive/My Drive/ML4NS1/cnn_mnist')\n",
        "    print(\"Saved\")\n",
        "    plt.plot(loss_plot)"
      ],
      "metadata": {
        "id": "do8k2osEPJMV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "CE6y1h0OPM98"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "id": "yyifDmNmY79k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d44908d9-67bd-45db-d97f-1ca5f2e1845c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  1000] loss: 0.935\n",
            "[1,  2000] loss: 0.316\n",
            "[1,  3000] loss: 0.223\n",
            "[1,  4000] loss: 0.206\n",
            "[1,  5000] loss: 0.137\n",
            "[1,  6000] loss: 0.144\n",
            "[1,  7000] loss: 0.141\n",
            "[1,  8000] loss: 0.143\n",
            "[1,  9000] loss: 0.155\n",
            "[1, 10000] loss: 0.134\n",
            "[1, 11000] loss: 0.120\n",
            "[1, 12000] loss: 0.127\n",
            "[1, 13000] loss: 0.109\n",
            "[1, 14000] loss: 0.114\n",
            "[1, 15000] loss: 0.105\n",
            "[1, 16000] loss: 0.080\n",
            "[1, 17000] loss: 0.089\n",
            "[1, 18000] loss: 0.084\n",
            "[1, 19000] loss: 0.059\n",
            "[1, 20000] loss: 0.080\n",
            "[1, 21000] loss: 0.062\n",
            "[1, 22000] loss: 0.062\n",
            "[1, 23000] loss: 0.105\n",
            "[1, 24000] loss: 0.067\n",
            "[1, 25000] loss: 0.053\n",
            "[1, 26000] loss: 0.084\n",
            "[1, 27000] loss: 0.098\n",
            "[1, 28000] loss: 0.064\n",
            "[1, 29000] loss: 0.089\n",
            "[1, 30000] loss: 0.058\n",
            "[1, 31000] loss: 0.078\n",
            "[1, 32000] loss: 0.078\n",
            "[1, 33000] loss: 0.029\n",
            "[1, 34000] loss: 0.076\n",
            "[1, 35000] loss: 0.068\n",
            "[1, 36000] loss: 0.085\n",
            "[1, 37000] loss: 0.075\n",
            "[1, 38000] loss: 0.058\n",
            "[1, 39000] loss: 0.052\n",
            "[1, 40000] loss: 0.044\n",
            "[1, 41000] loss: 0.082\n",
            "[1, 42000] loss: 0.070\n",
            "[1, 43000] loss: 0.061\n",
            "[1, 44000] loss: 0.075\n",
            "[1, 45000] loss: 0.057\n",
            "[1, 46000] loss: 0.033\n",
            "[1, 47000] loss: 0.085\n",
            "[1, 48000] loss: 0.053\n",
            "[1, 49000] loss: 0.057\n",
            "[1, 50000] loss: 0.062\n",
            "[1, 51000] loss: 0.050\n",
            "[1, 52000] loss: 0.066\n",
            "[1, 53000] loss: 0.066\n",
            "[1, 54000] loss: 0.076\n",
            "[1, 55000] loss: 0.050\n",
            "[1, 56000] loss: 0.065\n",
            "[1, 57000] loss: 0.051\n",
            "[1, 58000] loss: 0.074\n",
            "[1, 59000] loss: 0.031\n",
            "[1, 60000] loss: 0.054\n",
            "tensor(0.9839)\n",
            "[2,  1000] loss: 0.057\n",
            "[2,  2000] loss: 0.027\n",
            "[2,  3000] loss: 0.038\n",
            "[2,  4000] loss: 0.017\n",
            "[2,  5000] loss: 0.018\n",
            "[2,  6000] loss: 0.059\n",
            "[2,  7000] loss: 0.037\n",
            "[2,  8000] loss: 0.027\n",
            "[2,  9000] loss: 0.038\n",
            "[2, 10000] loss: 0.062\n",
            "[2, 11000] loss: 0.024\n",
            "[2, 12000] loss: 0.038\n",
            "[2, 13000] loss: 0.079\n",
            "[2, 14000] loss: 0.045\n",
            "[2, 15000] loss: 0.045\n",
            "[2, 16000] loss: 0.028\n",
            "[2, 17000] loss: 0.032\n",
            "[2, 18000] loss: 0.047\n",
            "[2, 19000] loss: 0.033\n",
            "[2, 20000] loss: 0.040\n",
            "[2, 21000] loss: 0.033\n",
            "[2, 22000] loss: 0.026\n",
            "[2, 23000] loss: 0.014\n",
            "[2, 24000] loss: 0.056\n",
            "[2, 25000] loss: 0.030\n",
            "[2, 26000] loss: 0.054\n",
            "[2, 27000] loss: 0.044\n",
            "[2, 28000] loss: 0.054\n",
            "[2, 29000] loss: 0.063\n",
            "[2, 30000] loss: 0.036\n",
            "[2, 31000] loss: 0.035\n",
            "[2, 32000] loss: 0.049\n",
            "[2, 33000] loss: 0.050\n",
            "[2, 34000] loss: 0.041\n",
            "[2, 35000] loss: 0.029\n",
            "[2, 36000] loss: 0.060\n",
            "[2, 37000] loss: 0.042\n",
            "[2, 38000] loss: 0.054\n",
            "[2, 39000] loss: 0.044\n",
            "[2, 40000] loss: 0.047\n",
            "[2, 41000] loss: 0.032\n",
            "[2, 42000] loss: 0.029\n",
            "[2, 43000] loss: 0.047\n",
            "[2, 44000] loss: 0.028\n",
            "[2, 45000] loss: 0.066\n",
            "[2, 46000] loss: 0.049\n",
            "[2, 47000] loss: 0.055\n",
            "[2, 48000] loss: 0.022\n",
            "[2, 49000] loss: 0.050\n",
            "[2, 50000] loss: 0.035\n",
            "[2, 51000] loss: 0.057\n",
            "[2, 52000] loss: 0.049\n",
            "[2, 53000] loss: 0.053\n",
            "[2, 54000] loss: 0.030\n",
            "[2, 55000] loss: 0.043\n",
            "[2, 56000] loss: 0.073\n",
            "[2, 57000] loss: 0.032\n",
            "[2, 58000] loss: 0.043\n",
            "[2, 59000] loss: 0.042\n",
            "[2, 60000] loss: 0.026\n",
            "tensor(0.9867)\n",
            "[3,  1000] loss: 0.039\n",
            "[3,  2000] loss: 0.024\n",
            "[3,  3000] loss: 0.015\n",
            "[3,  4000] loss: 0.014\n",
            "[3,  5000] loss: 0.020\n",
            "[3,  6000] loss: 0.020\n",
            "[3,  7000] loss: 0.037\n",
            "[3,  8000] loss: 0.041\n",
            "[3,  9000] loss: 0.030\n",
            "[3, 10000] loss: 0.023\n",
            "[3, 11000] loss: 0.042\n",
            "[3, 12000] loss: 0.037\n",
            "[3, 13000] loss: 0.019\n",
            "[3, 14000] loss: 0.039\n",
            "[3, 15000] loss: 0.020\n",
            "[3, 16000] loss: 0.037\n",
            "[3, 17000] loss: 0.030\n",
            "[3, 18000] loss: 0.026\n",
            "[3, 19000] loss: 0.042\n",
            "[3, 20000] loss: 0.041\n",
            "[3, 21000] loss: 0.069\n",
            "[3, 22000] loss: 0.030\n",
            "[3, 23000] loss: 0.053\n",
            "[3, 24000] loss: 0.032\n",
            "[3, 25000] loss: 0.040\n",
            "[3, 26000] loss: 0.028\n",
            "[3, 27000] loss: 0.049\n",
            "[3, 28000] loss: 0.030\n",
            "[3, 29000] loss: 0.026\n",
            "[3, 30000] loss: 0.012\n",
            "[3, 31000] loss: 0.033\n",
            "[3, 32000] loss: 0.040\n",
            "[3, 33000] loss: 0.032\n",
            "[3, 34000] loss: 0.034\n",
            "[3, 35000] loss: 0.032\n",
            "[3, 36000] loss: 0.045\n",
            "[3, 37000] loss: 0.007\n",
            "[3, 38000] loss: 0.046\n",
            "[3, 39000] loss: 0.040\n",
            "[3, 40000] loss: 0.035\n",
            "[3, 41000] loss: 0.018\n",
            "[3, 42000] loss: 0.032\n",
            "[3, 43000] loss: 0.047\n",
            "[3, 44000] loss: 0.046\n",
            "[3, 45000] loss: 0.032\n",
            "[3, 46000] loss: 0.019\n",
            "[3, 47000] loss: 0.015\n",
            "[3, 48000] loss: 0.020\n",
            "[3, 49000] loss: 0.076\n",
            "[3, 50000] loss: 0.038\n",
            "[3, 51000] loss: 0.040\n",
            "[3, 52000] loss: 0.030\n",
            "[3, 53000] loss: 0.029\n",
            "[3, 54000] loss: 0.029\n",
            "[3, 55000] loss: 0.019\n",
            "[3, 56000] loss: 0.035\n",
            "[3, 57000] loss: 0.022\n",
            "[3, 58000] loss: 0.025\n",
            "[3, 59000] loss: 0.018\n",
            "[3, 60000] loss: 0.011\n",
            "tensor(0.9905)\n",
            "[4,  1000] loss: 0.034\n",
            "[4,  2000] loss: 0.031\n",
            "[4,  3000] loss: 0.008\n",
            "[4,  4000] loss: 0.013\n",
            "[4,  5000] loss: 0.015\n",
            "[4,  6000] loss: 0.025\n",
            "[4,  7000] loss: 0.021\n",
            "[4,  8000] loss: 0.012\n",
            "[4,  9000] loss: 0.014\n",
            "[4, 10000] loss: 0.019\n",
            "[4, 11000] loss: 0.014\n",
            "[4, 12000] loss: 0.036\n",
            "[4, 13000] loss: 0.036\n",
            "[4, 14000] loss: 0.025\n",
            "[4, 15000] loss: 0.038\n",
            "[4, 16000] loss: 0.023\n",
            "[4, 17000] loss: 0.016\n",
            "[4, 18000] loss: 0.024\n",
            "[4, 19000] loss: 0.041\n",
            "[4, 20000] loss: 0.024\n",
            "[4, 21000] loss: 0.023\n",
            "[4, 22000] loss: 0.016\n",
            "[4, 23000] loss: 0.037\n",
            "[4, 24000] loss: 0.009\n",
            "[4, 25000] loss: 0.027\n",
            "[4, 26000] loss: 0.030\n",
            "[4, 27000] loss: 0.028\n",
            "[4, 28000] loss: 0.017\n",
            "[4, 29000] loss: 0.022\n",
            "[4, 30000] loss: 0.034\n",
            "[4, 31000] loss: 0.026\n",
            "[4, 32000] loss: 0.056\n",
            "[4, 33000] loss: 0.045\n",
            "[4, 34000] loss: 0.020\n",
            "[4, 35000] loss: 0.036\n",
            "[4, 36000] loss: 0.031\n",
            "[4, 37000] loss: 0.028\n",
            "[4, 38000] loss: 0.025\n",
            "[4, 39000] loss: 0.009\n",
            "[4, 40000] loss: 0.052\n",
            "[4, 41000] loss: 0.020\n",
            "[4, 42000] loss: 0.023\n",
            "[4, 43000] loss: 0.028\n",
            "[4, 44000] loss: 0.045\n",
            "[4, 45000] loss: 0.039\n",
            "[4, 46000] loss: 0.026\n",
            "[4, 47000] loss: 0.016\n",
            "[4, 48000] loss: 0.017\n",
            "[4, 49000] loss: 0.054\n",
            "[4, 50000] loss: 0.018\n",
            "[4, 51000] loss: 0.051\n",
            "[4, 52000] loss: 0.034\n",
            "[4, 53000] loss: 0.013\n",
            "[4, 54000] loss: 0.034\n",
            "[4, 55000] loss: 0.044\n",
            "[4, 56000] loss: 0.025\n",
            "[4, 57000] loss: 0.011\n",
            "[4, 58000] loss: 0.016\n",
            "[4, 59000] loss: 0.037\n",
            "[4, 60000] loss: 0.035\n",
            "tensor(0.9906)\n",
            "[5,  1000] loss: 0.015\n",
            "[5,  2000] loss: 0.016\n",
            "[5,  3000] loss: 0.019\n",
            "[5,  4000] loss: 0.047\n",
            "[5,  5000] loss: 0.020\n",
            "[5,  6000] loss: 0.013\n",
            "[5,  7000] loss: 0.021\n",
            "[5,  8000] loss: 0.009\n",
            "[5,  9000] loss: 0.007\n",
            "[5, 10000] loss: 0.029\n",
            "[5, 11000] loss: 0.026\n",
            "[5, 12000] loss: 0.019\n",
            "[5, 13000] loss: 0.012\n",
            "[5, 14000] loss: 0.033\n",
            "[5, 15000] loss: 0.016\n",
            "[5, 16000] loss: 0.028\n",
            "[5, 17000] loss: 0.028\n",
            "[5, 18000] loss: 0.015\n",
            "[5, 19000] loss: 0.018\n",
            "[5, 20000] loss: 0.023\n",
            "[5, 21000] loss: 0.009\n",
            "[5, 22000] loss: 0.024\n",
            "[5, 23000] loss: 0.025\n",
            "[5, 24000] loss: 0.031\n",
            "[5, 25000] loss: 0.027\n",
            "[5, 26000] loss: 0.032\n",
            "[5, 27000] loss: 0.010\n",
            "[5, 28000] loss: 0.016\n",
            "[5, 29000] loss: 0.028\n",
            "[5, 30000] loss: 0.028\n",
            "[5, 31000] loss: 0.021\n",
            "[5, 32000] loss: 0.024\n",
            "[5, 33000] loss: 0.025\n",
            "[5, 34000] loss: 0.028\n",
            "[5, 35000] loss: 0.036\n",
            "[5, 36000] loss: 0.028\n",
            "[5, 37000] loss: 0.027\n",
            "[5, 38000] loss: 0.015\n",
            "[5, 39000] loss: 0.019\n",
            "[5, 40000] loss: 0.012\n",
            "[5, 41000] loss: 0.033\n",
            "[5, 42000] loss: 0.029\n",
            "[5, 43000] loss: 0.034\n",
            "[5, 44000] loss: 0.016\n",
            "[5, 45000] loss: 0.020\n",
            "[5, 46000] loss: 0.017\n",
            "[5, 47000] loss: 0.021\n",
            "[5, 48000] loss: 0.033\n",
            "[5, 49000] loss: 0.013\n",
            "[5, 50000] loss: 0.018\n",
            "[5, 51000] loss: 0.029\n",
            "[5, 52000] loss: 0.023\n",
            "[5, 53000] loss: 0.015\n",
            "[5, 54000] loss: 0.031\n",
            "[5, 55000] loss: 0.025\n",
            "[5, 56000] loss: 0.008\n",
            "[5, 57000] loss: 0.028\n",
            "[5, 58000] loss: 0.059\n",
            "[5, 59000] loss: 0.018\n",
            "[5, 60000] loss: 0.028\n",
            "tensor(0.9895)\n",
            "Finished Training, saving\n",
            "Saved\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4d8g5qH7Rto"
      },
      "outputs": [],
      "source": [
        "train_data0 = np.load('/content/drive/My Drive/ML4NS1/data0.npy')\n",
        "train_lab0 = np.load('/content/drive/My Drive/ML4NS1/lab0.npy')\n",
        "train_data1 = np.load('/content/drive/My Drive/ML4NS1/data1.npy')\n",
        "train_lab1 = np.load('/content/drive/My Drive/ML4NS1/lab1.npy')\n",
        "train_data2 = np.load('/content/drive/My Drive/ML4NS1/data2.npy')\n",
        "train_lab2 = np.load('/content/drive/My Drive/ML4NS1/lab2.npy')\n",
        "\n",
        "train_data = np.concatenate((train_data0, train_data1, train_data2))\n",
        "train_lab = np.concatenate((train_lab0, train_lab1, train_lab2))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def deskew(img):\n",
        "    m = cv2.moments(img)\n",
        "    if abs(m['mu02']) < 1e-2:\n",
        "        return img.copy()\n",
        "    skew = m['mu11']/m['mu02']\n",
        "    M = np.float32([[1, skew, -0.5*28*skew], [0, 1, 0]])\n",
        "    img = cv2.warpAffine(img, M, (28, 28), flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "UDCX7ptjXUUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(image):\n",
        "    ret, thresh = cv2.threshold(image,50,150,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    connectivity = 8  \n",
        "    output = cv2.connectedComponentsWithStats(thresh, connectivity, cv2.CV_32S)\n",
        "    stats = output[2]\n",
        "    segments = []\n",
        "    for i in range(1,len(stats)):\n",
        "        l,t,w,h,a = stats[i]\n",
        "        cropped = image[t:t+h,l:l+w]\n",
        "        if a >= 30:\n",
        "            if w > 22 and w<=37:\n",
        "                splitted1=image[t:t+h, l:l+int(w/2)]\n",
        "                splitted2=image[t:t+h, l+int(w/2):l+w]\n",
        "\n",
        "                splitted1 = cv2.resize(splitted1, (0,0), fx=0.78, fy=0.78, interpolation = cv2.INTER_AREA) \n",
        "                splitted2 = cv2.resize(splitted2, (0,0), fx=0.78, fy=0.78, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "                pad_shape = np.array([28, 28]) - np.array(splitted1.shape)\n",
        "                splitted1 = np.pad(splitted1, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                splitted1 = deskew(splitted1)\n",
        "                segments.append(splitted1)\n",
        "\n",
        "                pad_shape = np.array([28, 28]) - np.array(splitted2.shape)\n",
        "                splitted2 = np.pad(splitted2, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                splitted2 = deskew(splitted2)\n",
        "                segments.append(splitted2)\n",
        "            \n",
        "            elif w>37:\n",
        "                splitted1=image[t:t+h, l:l+int(w/3)]\n",
        "                splitted2=image[t:t+h, l+int(w/3):l+int(2*w/3)]\n",
        "                splitted3=image[t:t+h, l+int(2*w/3):l+w]\n",
        "\n",
        "                splitted1 = cv2.resize(splitted1, (0,0), fx=0.78, fy=0.78, interpolation = cv2.INTER_AREA) \n",
        "                splitted2 = cv2.resize(splitted2, (0,0), fx=0.78, fy=0.78, interpolation = cv2.INTER_AREA)\n",
        "                splitted3 = cv2.resize(splitted3, (0,0), fx=0.78, fy=0.78, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "                pad_shape = np.array([28, 28]) - np.array(splitted1.shape)\n",
        "                splitted1 = np.pad(splitted1, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                splitted1 = deskew(splitted1)\n",
        "                segments.append(splitted1)\n",
        "\n",
        "                pad_shape = np.array([28, 28]) - np.array(splitted2.shape)\n",
        "                splitted2 = np.pad(splitted2, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                splitted2 = deskew(splitted2)\n",
        "                segments.append(splitted2)\n",
        "\n",
        "                pad_shape = np.array([28, 28]) - np.array(splitted3.shape)\n",
        "                splitted3 = np.pad(splitted3, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                splitted3 = deskew(splitted3)\n",
        "                segments.append(splitted3)\n",
        "\n",
        "            else:\n",
        "                if h>28:\n",
        "                    cropped = cv2.resize(cropped, (0,0), fx=0.8, fy=0.8, interpolation = cv2.INTER_AREA)\n",
        "                pad_shape = np.array([28, 28]) - np.array(cropped.shape)\n",
        "                cropped = np.pad(cropped, ((pad_shape[0] // 2, (pad_shape[0] + 1) // 2), (pad_shape[1] // 2, (pad_shape[1] + 1) // 2)))\n",
        "                cropped = deskew(cropped)\n",
        "                segments.append(cropped)\n",
        "    return segments\n",
        "    "
      ],
      "metadata": {
        "id": "8s-6S1qswlam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model_path, train_data, train_lab):\n",
        "    predictor = torch.load(model_path)\n",
        "    predictor.to(device)\n",
        "    acc = []\n",
        "    counter = 0\n",
        "    falsectr = 0\n",
        "    for i in range(len(train_data)):\n",
        "        img = train_data[i]\n",
        "        labels = train_lab[i]     \n",
        "        inputs = split(img)\n",
        "        sum = 0\n",
        "        digits = []\n",
        "        for j in range(len(inputs)):\n",
        "            image = torch.from_numpy(inputs[j])\n",
        "            image = torch.reshape(image, (1,1,28,28)).float()\n",
        "            outputs = predictor(image.to(device))\n",
        "            digit = torch.argmax(outputs)\n",
        "            digits.append(digit)\n",
        "            sum += digit\n",
        "        if sum == labels:\n",
        "            counter+=1\n",
        "        if i % 500 == 499:    # print every 5000\n",
        "                print('%d, accuracy: %.3f' %\n",
        "                        ( i+1, counter*100 / i))\n",
        "    print(\"Final accuracy \"+str(counter*100/len(train_data))+\"%\")\n"
      ],
      "metadata": {
        "id": "vD2EFyv2ASLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict('/content/drive/My Drive/ML4NS1/cnn_mnist',  train_data, train_lab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYY33VJygWqm",
        "outputId": "0b6ed4df-c8fb-4992-e003-df96f3d138ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500, accuracy: 63.928\n",
            "1000, accuracy: 64.765\n",
            "1500, accuracy: 64.243\n",
            "2000, accuracy: 63.582\n",
            "2500, accuracy: 62.745\n",
            "3000, accuracy: 63.288\n",
            "3500, accuracy: 63.818\n",
            "4000, accuracy: 64.241\n",
            "4500, accuracy: 64.570\n",
            "5000, accuracy: 64.333\n",
            "5500, accuracy: 64.394\n",
            "6000, accuracy: 64.061\n",
            "6500, accuracy: 63.933\n",
            "7000, accuracy: 63.952\n",
            "7500, accuracy: 63.742\n",
            "8000, accuracy: 63.620\n",
            "8500, accuracy: 63.607\n",
            "9000, accuracy: 63.396\n",
            "9500, accuracy: 63.459\n",
            "10000, accuracy: 63.436\n",
            "10500, accuracy: 63.397\n",
            "11000, accuracy: 63.451\n",
            "11500, accuracy: 63.449\n",
            "12000, accuracy: 63.514\n",
            "12500, accuracy: 63.397\n",
            "13000, accuracy: 63.336\n",
            "13500, accuracy: 63.345\n",
            "14000, accuracy: 63.226\n",
            "14500, accuracy: 63.184\n",
            "15000, accuracy: 63.198\n",
            "15500, accuracy: 63.223\n",
            "16000, accuracy: 63.298\n",
            "16500, accuracy: 63.319\n",
            "17000, accuracy: 63.286\n",
            "17500, accuracy: 63.284\n",
            "18000, accuracy: 63.381\n",
            "18500, accuracy: 63.355\n",
            "19000, accuracy: 63.340\n",
            "19500, accuracy: 63.388\n",
            "20000, accuracy: 63.308\n",
            "20500, accuracy: 63.330\n",
            "21000, accuracy: 63.246\n",
            "21500, accuracy: 63.268\n",
            "22000, accuracy: 63.298\n",
            "22500, accuracy: 63.296\n",
            "23000, accuracy: 63.277\n",
            "23500, accuracy: 63.262\n",
            "24000, accuracy: 63.269\n",
            "24500, accuracy: 63.190\n",
            "25000, accuracy: 63.243\n",
            "25500, accuracy: 63.238\n",
            "26000, accuracy: 63.237\n",
            "26500, accuracy: 63.331\n",
            "27000, accuracy: 63.339\n",
            "27500, accuracy: 63.366\n",
            "28000, accuracy: 63.409\n",
            "28500, accuracy: 63.420\n",
            "29000, accuracy: 63.430\n",
            "29500, accuracy: 63.406\n",
            "30000, accuracy: 63.425\n",
            "Final accuracy 63.42333333333333%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-LTA_uBvsnSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fbEqWG4rwU-Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "predict_sum.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}